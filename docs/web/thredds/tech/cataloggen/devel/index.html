<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
  
  <meta content="text/html; charset=iso-8859-1" http-equiv="content-type"><title>Catalog Generation Developement</title>
  

  
  
  <meta content="Ethan Davis" name="author"></head>
<body>
<h1>Catalog Generation Development<br>
</h1>

<hr size="2" width="100%"><br>
<hr size="2" width="100%">Contents:<br>

<ul>

  <li><a href="#Features">Features</a></li>
  <li><a href="#Issues">Issues</a></li></ul>Related Documents:<br>
<ul>
  <li><a href="architecture.html">CrawlableDataset/CatalogBuilder/DatasetScan framework</a></li>
  <li><a href="datasetScanElement.html">datasetScan element</a></li>
  <li><a href="userImplementation.html">Implementing CrawlableDataset and Related Interfaces<br>
    </a></li>
</ul>

<hr size="2" width="100%">
<h2><a name="Features"></a>Features</h2><h3>Features for next round of development (2006- to 2006-)<br>
</h3>
<ul>
  <li>Add CrawlableDataset.exists() method so constructor doesn't
have to throw IOExceptions. Would also free
CrawlableDataset.listDatasets(...) to not throw IOExceptions. How would
this affect CatalogBuilder IOExceptions? Need to look at
CollectionLevelScanner and various CatalogBuilder impls before
deciding. Also look at CatalogBuilder.requestCrawlableDataset(): drop
IOException and maybe IllegalStateException.<br>
</li><li>Consider changing CatalogBuilder to CollectionRoot now that it is
not just for catalogs. For instance, it now also checks that a path is
a valid dataset in this collection and returns a CrawlableDataset for
that path (which provides user with a dataset access mechanism).</li>

  <li>Need clean seperation between use of URL path and use of CrawlableDataset path (i.e., datasetScan@location).
Should CatalogRootHandler or InvDatasetScan deal with mapping between
URL path and CrawlableDataset path? Currently done in both locations
depending on circumstance. Probably should be done in
CatalogRootHandler with translatePath() methods (though it doesn't look
like translatePath() methods are currently used by CatalogRootHandler).<br>
  </li>
  <li>Look at thread safety of the InvDatasetScan,
DatasetScanCatalogBuilder, StandardCatalogBuilder,
CollectionLevelScanner chain of classes. (Each instance of
InvDatasetScan is kept by servlet between each reinit. Other classes
listed are created with each call. Is there a better way?)<br>
  </li>
  <li>Figure out how and whether to deal with CrDs:</li>
  <ul>
    <li>root path "/"</li>
    <li>path segment self reference, i.e., "."</li>
    <li>path segment parent reference, i.e., ".."<br>
    </li>
  </ul>
</ul>
<h3>Features for next round of development</h3>








<ul><li>Allow different configs at different levels of a collection</li>
  <ul>
<li>datasetScan elements nested inside datasetScan (only deal with one level of nesting, paths can be multiple levels)<br>
      </li><li>datasetScan element in standard file&nbsp; (tdsMetadata.xml OR tdsDatasetScan.xml?)
in directory that corresponds with CrawlableDataset collection level:
be flexible on what is allowed (e.g., a full datasetScan; a metadata
element; text with name/value pairs; text description); provide an
interface that allows access to datasetScan type
metadata (like CrawlableDataset, given a "path/name" return datasetScan
information)</li><li>allow access from datasetScan element to user implemented thredds.cataloggen.ScannerInfoAccess interface</li>
  </ul><li>Convert CatalogGen and DatasetSource (?) to use CrawlableDataset framework</li>
  <ul>
<li>ask thredds list if anyone is using DatasetSource API</li><li>how deal with old CatGenConfig files</li><ul><li>read into InvDatasetScan</li><li>convert to datasetScan<br>
      </li><li>drop support (still works with old versions of of code, if need new features, need to move to new code)???<br>
      </li></ul>
  </ul>
  <li>Reinstate CrawlableDatasetAlias once we:<br>
</li>
  <ul>
    <li>Figure out how to handle things like ".scour*" being a regular file.</li>
  </ul>
  <li>Extend CrawlableDatasetAlias to allow "?" and "**" as wildcards, if succeed with above.<br>
  </li>

  <li>Sort on InvDataset instead of CrawlableDataset and do the sort
after dataset is named and enhanced (see
CollectionLevelScanner.generateCatalog()). As is, we can't use naming
or enhancements to determine sort order. [Might require an additional call to catalog.finish(). Argh!]<br>
  </li>
  <li>Drop DirectoryScanner support???</li>
  <li>When have CrawlableDataset where isCollection() give "true", allow
    config for these two options: 1) add a catalogRef; 2) check for any child
    datasets before adding a catalogRef, if no children, don't add
    catalogRef, if children, add catalogRef.</li>


</ul>


<h3>Future Features</h3>


<ol><li>Review CatalogGen and DatasetSource for features not in InvDatasetScan</li><li>Make use of 3rd-party implementations consistent (CrawlableDataset, CrawlableDatasetFilter, DatasetEnhancer, etc)</li><li>Review logging and error/exception stuff (Nathan wants stack trace info for debugging, etc)<br>
  </li>

<li>Use catalog mapping mechanism in data server</li>
  <ul>
    <li>Look
at using CrawlableDataset framework in data server to map from request
URL to actual data resource to be served (currently done in
thredds.servlet.CatalogHandler by mapping request URL to string to
File). How do this in general way where data resource may not be a
local file? These two pieces of functionality come to mind:<br>
    </li>
  </ul>
  <ul>
    <ul>
      <li>Server needs to be able to determine if request URL maps to a
data resource that should be served (is available and is not filtered
out). Maybe an InvDatasetScan method like isSupportedDatasetResouce(
String).</li>
    </ul>
    <ul>
      <li>Server
needs to be able to access the data resource the request URL maps to.
Maybe a CrawlableDataset method like getAccessURL(). But how does
server know what kind of Object the URL resolves to? Is URL/URI general
enough?</li>
    </ul>
    <li>How should the "Latest" mechanism in
cataloging map to data
server and "Latest" service? Should addLatest (besides specifying name,
service, and access URL)indicate how a query to the "Latest" service is
handled (e.g., find dataset whose name is lexigraphically biggest)? </li>
  </ul>
  <li>Modify structure of collection/catalog</li>
  <ul>
<li>CrawlableDatasetAlias can be used to change the structure of a
collection by flattening (wildcard to combine directories) or adding
levels (wildcard to select a subgroup from one collection level).
Another option, if needed, would be a specialized implementation of
CrawlableDataset that modified collection structure as desired. <b>So, postponing/dropping inclusion of &lt;structure&gt; element in the datasetScan refactor.</b></li><li>Still need a way to expand catalogRefs to build multi-level catalogs. <b>Will look at adding an expandCatalogRefs element in datasetScan.</b></li>
  </ul>
  <li>??Provide method for getting metadata (as String of XML) from CrawlableDataset (getMetadata():String).</li>
</ol>


<br>


<hr size="2" width="100%">
<h2><a name="Issues"></a>Issues</h2>


<ul>
<li>Does CrawlableDatasetAlias need to have non-wildcard path and name
(so that datasets like Latest can use it's path as their base)? <br>
</li><li>Latest dataset</li>
  <ul>
    <li>Latest CrawlableDataset doesn't have file (or whatever) behind it. <br>
    </li>
    <ul>
      <li>Use private member class to implement CrawlableDataset (as in SimpleLatestInserter)</li>
      <li>OR Use a proxy CrawlableDataset to represent it (pointing to what?)</li>
      <li>OR ???<br>
      </li>
    </ul>
  </ul>
  <li>Need to deal with static vs dynamic catalogs and cacheing<br>
  </li>
<ul><li>Add methods to CrawlableDataset to</li><ul><li>provide info about expected lifetime of collection, e.g., expires():Date</li><li>provide capability to check validity of existing catalog, e.g., changedSince(Date):boolean </li></ul><li>Want to support</li><ul><li>one time generation of catalogs</li><li>routine generation of catalogs</li><ul><li>repeat after certain period of time (every 15 min or 3 days)</li><li>at standard times (quarter after every hour (hh:15); the 5th of every month (yyyy-mm-05T00:00))</li></ul><li>generate catalogs upon request<br>
      </li><li>Cacheing of catalogs</li><ul><li>provide expiration dates</li><li>check with server if old version still valid</li></ul><li>HTTP deals with both expiration and validation cacheing <br>
      </li></ul></ul><li>What do we want implementors to have to implement?</li><ul><li>CrawlableDataset</li><li>CrawlableDatasetIdentifier</li><li>CrawlableDatasetNamer (should be CrawlableDatasetLabeler? since CrawlableDataset has an intrinsic name)<br>
    </li><li>DatasetEnhancer ???<br>
    </li><ul><li>implementor needs to understand InvDataset and InvMetadata</li><li>What if implementor wants to add FGDC metadata to dataset? Need CrawlableDatasetEnhancer that returns XML as string?</li></ul></ul>
</ul><br>
<hr size="2" width="100%">
<h2>Completed Features</h2>
<h3>Features added 2006-1-20 to 2006-1-26</h3>


<ul>
<li>CatGen: split CatalogGen.main() out into CatalogGenMain.main()</li><li>Check that given path is an allowed CrawlableDataset for the
collection root (affects this chain of classes CatalogRootHandler,
InvDatasetScan, DatasetScanCatalogBuilder, StandardCatalogBuilder).</li><li>Log error/warning when bad values in addTimeCoverage element instead of throwing exception.<br>
  </li>
</ul>


<h3>pre-Nov 2005 to Jan 2006 - refactor CatGen to use CrawlableDataset/CatalogBuilder framework</h3>
<p>The TDS configuration is done with datasetScan and datasetRoot
elements. The current InvDatasetScan implementation behind the scenes
uses java.util.File (and CataloGen/DatasetSource) to crawl through local files and create catalogs.<br>
</p>

This refactor of CatalogGen and InvDatasetScan is being done mainly
to allow for the generation of catalogs using other types of data
sources (remote data, database, etc). The CrawlableDataset interface is
a generalization (and simplification) of java.util.File. InvDatasetScan
and CatalogGen/DatasetSource will be modified to use the
CrawlableDataset interface instead of java.util.File to crawl the
desired dataset.<br>

<ul>
<li>Ability to subset a collection, flatten nested collections, and add
collection layers using CrawlableDatasetAlias</li><ul><li>Implement use of CrDsAlias in CrDsFactory</li><li>Implement&nbsp; InvDatasetScan  etc</li><li>Make sure alias stuff work for latest, etc<br>
    </li></ul><li>Filter on CrawlableDataset name using include/exclude regular expression and wildcard patterns to include and exclude datasets<br>
  </li><li>Add ID using baseID (or datasetScan path) and CrawlableDataset path (minus collection level path)<br>
  </li><li>Sort each level up or down lexigraphically by CrawlableDataset name<br>
  </li><li>Add latest dataset</li><ul><li>Add as first or last dataset in collection</li></ul><li>Add dataset size in bytes<br>
  </li><li>Add time coverage</li><ul><li>datasetNameMatchPattern (or datasetPathMatchPattern)</li><li>startTimeSubstitutionPattern</li><li>duration<br>
    </li></ul><li>Make sure CrawlableDatasetAlias can deal with any impl of CrawlableDataset</li><ul><li>Change how factory stuff works<br>
    </li></ul>
</ul>
<br>




<hr size="2" width="100%">
</body></html>